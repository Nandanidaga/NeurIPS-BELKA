{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920e6da8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-25T13:06:35.028156Z",
     "iopub.status.busy": "2024-06-25T13:06:35.027890Z",
     "iopub.status.idle": "2024-06-25T13:06:40.781724Z",
     "shell.execute_reply": "2024-06-25T13:06:40.780840Z"
    },
    "papermill": {
     "duration": 5.765046,
     "end_time": "2024-06-25T13:06:40.784416",
     "exception": false,
     "start_time": "2024-06-25T13:06:35.019370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91911ab5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-25T13:06:40.798255Z",
     "iopub.status.busy": "2024-06-25T13:06:40.798008Z",
     "iopub.status.idle": "2024-06-25T13:06:42.070875Z",
     "shell.execute_reply": "2024-06-25T13:06:42.070052Z"
    },
    "papermill": {
     "duration": 1.282309,
     "end_time": "2024-06-25T13:06:42.073097",
     "exception": false,
     "start_time": "2024-06-25T13:06:40.790788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffee711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:06:42.087048Z",
     "iopub.status.busy": "2024-06-25T13:06:42.086703Z",
     "iopub.status.idle": "2024-06-25T13:06:42.091279Z",
     "shell.execute_reply": "2024-06-25T13:06:42.090398Z"
    },
    "papermill": {
     "duration": 0.013977,
     "end_time": "2024-06-25T13:06:42.093522",
     "exception": false,
     "start_time": "2024-06-25T13:06:42.079545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    predict = True\n",
    "    PREPROCESS = False\n",
    "    EPOCHS = 18\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-3\n",
    "    WD = 0.05\n",
    "\n",
    "    NBR_FOLDS = 15\n",
    "    SELECTED_FOLDS = [0]\n",
    "\n",
    "    SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c504e90b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-25T13:06:42.109729Z",
     "iopub.status.busy": "2024-06-25T13:06:42.109128Z",
     "iopub.status.idle": "2024-06-25T13:07:21.287766Z",
     "shell.execute_reply": "2024-06-25T13:07:21.286848Z"
    },
    "papermill": {
     "duration": 39.188283,
     "end_time": "2024-06-25T13:07:21.290059",
     "exception": false,
     "start_time": "2024-06-25T13:06:42.101776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D0625 13:07:13.474424543      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D0625 13:07:13.474447810      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D0625 13:07:13.474451732      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D0625 13:07:13.474454490      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\n",
      "D0625 13:07:13.474457074      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D0625 13:07:13.474459943      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D0625 13:07:13.474462498      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\n",
      "D0625 13:07:13.474465524      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D0625 13:07:13.474467943      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D0625 13:07:13.474470461      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D0625 13:07:13.474473022      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D0625 13:07:13.474475628      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D0625 13:07:13.474478256      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D0625 13:07:13.474480773      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "I0625 13:07:13.474704086      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 60\n",
      "D0625 13:07:13.474717611      14 ev_posix.cc:144]                      Using polling engine: epoll1\n",
      "D0625 13:07:13.474737440      14 dns_resolver_ares.cc:822]             Using ares dns resolver\n",
      "D0625 13:07:13.475248955      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0625 13:07:13.475257027      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0625 13:07:13.475260663      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0625 13:07:13.475263883      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0625 13:07:13.475267036      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0625 13:07:13.475270198      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\n",
      "D0625 13:07:13.475278682      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0625 13:07:13.475295755      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0625 13:07:13.475343703      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0625 13:07:13.475361513      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0625 13:07:13.475365284      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0625 13:07:13.475368703      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0625 13:07:13.475372795      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D0625 13:07:13.475376358      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0625 13:07:13.475379781      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0625 13:07:13.475384662      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\n",
      "I0625 13:07:13.479367644      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0625 13:07:13.516409793      14 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0625 13:07:13.522556906      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-06-25T13:07:13.52253958+00:00\", grpc_status:2}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7091bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:07:21.303848Z",
     "iopub.status.busy": "2024-06-25T13:07:21.303377Z",
     "iopub.status.idle": "2024-06-25T13:07:30.170680Z",
     "shell.execute_reply": "2024-06-25T13:07:30.169445Z"
    },
    "papermill": {
     "duration": 8.879953,
     "end_time": "2024-06-25T13:07:30.175941",
     "exception": false,
     "start_time": "2024-06-25T13:07:21.295988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "Running on TPU\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU\")\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "    all_data = True\n",
    "except tf.errors.NotFoundError:\n",
    "    all_data = False\n",
    "\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(\"Not on TPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8ace7",
   "metadata": {
    "papermill": {
     "duration": 0.006858,
     "end_time": "2024-06-25T13:07:30.190040",
     "exception": false,
     "start_time": "2024-06-25T13:07:30.183182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c459ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:07:30.205160Z",
     "iopub.status.busy": "2024-06-25T13:07:30.204916Z",
     "iopub.status.idle": "2024-06-25T13:07:48.265736Z",
     "shell.execute_reply": "2024-06-25T13:07:48.264658Z"
    },
    "papermill": {
     "duration": 18.071359,
     "end_time": "2024-06-25T13:07:48.268024",
     "exception": false,
     "start_time": "2024-06-25T13:07:30.196665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\r\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\r\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (23.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.6.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.65.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.12.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2023.5.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (1.26.16)\r\n",
      "Installing collected packages: huggingface-hub, tokenizers\r\n",
      "Successfully installed huggingface-hub-0.23.4 tokenizers-0.19.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers) (3.12.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from transformers) (0.23.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers) (1.23.5)\r\n",
      "Collecting safetensors>=0.4.1\r\n",
      "  Downloading safetensors-0.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting regex!=2019.12.17\r\n",
      "  Downloading regex-2024.5.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.2/776.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.8/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.6.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Installing collected packages: safetensors, regex, transformers\r\n",
      "Successfully installed regex-2024.5.15 safetensors-0.4.3 transformers-4.41.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31acf1d6",
   "metadata": {
    "papermill": {
     "duration": 0.008184,
     "end_time": "2024-06-25T13:07:48.284871",
     "exception": false,
     "start_time": "2024-06-25T13:07:48.276687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create a tokenizer\n",
    "\n",
    "We use Tokenizer and PreTrainedTokenizerFast,\n",
    "\n",
    "First create the dictionary enc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c7f15c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:07:48.303565Z",
     "iopub.status.busy": "2024-06-25T13:07:48.303232Z",
     "iopub.status.idle": "2024-06-25T13:08:07.508747Z",
     "shell.execute_reply": "2024-06-25T13:08:07.507874Z"
    },
    "papermill": {
     "duration": 19.217443,
     "end_time": "2024-06-25T13:08:07.510915",
     "exception": false,
     "start_time": "2024-06-25T13:07:48.293472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers.models import WordLevel,BPE\n",
    "\n",
    "from tokenizers.pre_tokenizers import Whitespace,Split,ByteLevel\n",
    "\n",
    "from tokenizers.normalizers import Lowercase, NFKC\n",
    "\n",
    "enc = { '[PAD]':0,\n",
    "        'Br':1, 'C':2, 'N':3, 'O':4, 'H':5, 'S':6, 'F':7, 'Cl':8, 'B':9, 'I':10, \n",
    "        's':11,'o':12, 'c':13, 'n':14, 'i':15, # is Atomic\n",
    "        '.':16 ,'=':17 ,'#':18, # bond\n",
    "        '/':19, # direction\n",
    "        '-':20, '+': 21, # charge\n",
    "        '[':22,']':23, # Atomic mass\n",
    "        '(':24,')':25, # Branches\n",
    "        '@@':26, '@':27, # tetrahedron\n",
    "        '1':28,'2':29,'3':30,'4':31,'5':32,'6':33,'7':34,'8':35,'9':36\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c8a9b",
   "metadata": {
    "papermill": {
     "duration": 0.008252,
     "end_time": "2024-06-25T13:08:07.527892",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.519640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Then create a Tokenizer with BPE\n",
    "Pay attention to ```merges```. In the case that both @ and @@ exist, we should find @@ first, then @\n",
    "\n",
    "then converted to PreTrainedTokenizerFast\n",
    "\n",
    "Create special tokens at the same time\n",
    "\n",
    "Also, we should set [Dy] to sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10f96aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.546129Z",
     "iopub.status.busy": "2024-06-25T13:08:07.545667Z",
     "iopub.status.idle": "2024-06-25T13:08:07.557311Z",
     "shell.execute_reply": "2024-06-25T13:08:07.556669Z"
    },
    "papermill": {
     "duration": 0.022819,
     "end_time": "2024-06-25T13:08:07.558962",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.536143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(vocab=enc, unk_token=\"[UNK]\",merges=[('@','@')]))\n",
    "\n",
    "tokenizer_fast = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "tokenizer_fast.add_special_tokens({'pad_token': '[PAD]','sep_token':'[Dy]'})\n",
    "tokenizer_fast.add_special_tokens({'additional_special_tokens':['Br','Cl']})\n",
    "\n",
    "len(set(enc.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a10d9bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.576998Z",
     "iopub.status.busy": "2024-06-25T13:08:07.576768Z",
     "iopub.status.idle": "2024-06-25T13:08:07.581366Z",
     "shell.execute_reply": "2024-06-25T13:08:07.580666Z"
    },
    "papermill": {
     "duration": 0.015785,
     "end_time": "2024-06-25T13:08:07.583182",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.567397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 0, 1, 8]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fast.all_special_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8796684",
   "metadata": {
    "papermill": {
     "duration": 0.008239,
     "end_time": "2024-06-25T13:08:07.599486",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.591247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Then implement batch spliting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f649dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.617984Z",
     "iopub.status.busy": "2024-06-25T13:08:07.617734Z",
     "iopub.status.idle": "2024-06-25T13:08:07.621354Z",
     "shell.execute_reply": "2024-06-25T13:08:07.620614Z"
    },
    "papermill": {
     "duration": 0.015002,
     "end_time": "2024-06-25T13:08:07.623184",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.608182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def compile_model():\n",
    "#     with strategy.scope():\n",
    "#         model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Dense(64, input_shape=(64,))\n",
    "#         ])\n",
    "#         model.compile(metrics=['accuracy'])\n",
    "#         return model\n",
    "# model = compile_model()\n",
    "# dummy_input = tf.random.uniform((1, 64))\n",
    "# output = model(dummy_input)\n",
    "# print(\"TPU shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89c21ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.642430Z",
     "iopub.status.busy": "2024-06-25T13:08:07.642135Z",
     "iopub.status.idle": "2024-06-25T13:08:07.648696Z",
     "shell.execute_reply": "2024-06-25T13:08:07.647956Z"
    },
    "papermill": {
     "duration": 0.018571,
     "end_time": "2024-06-25T13:08:07.650399",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.631828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def encode_smiles_batch(smiles_chunk, max_length=142, batch_size=32):\n",
    "    encoded_batch = tokenizer_fast.batch_encode_plus(\n",
    "        smiles_chunk,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        return_tensors='np',\n",
    "        truncation=True\n",
    "    )['input_ids']\n",
    "\n",
    "    return encoded_batch.astype(np.int8)\n",
    "\n",
    "def encode_smiles_parallel(smiles, max_length=142, batch_size=4096*8):\n",
    "    smiles_chunks = [smiles[i:i + batch_size] for i in range(0, len(smiles), batch_size)]\n",
    "    encoded_chunks = Parallel(n_jobs=-1)(delayed(encode_smiles_batch)(chunk, max_length, batch_size) for chunk in tqdm(smiles_chunks))\n",
    "    \n",
    "    encoded_smiles = np.concatenate(encoded_chunks, axis=0)\n",
    "    \n",
    "    return encoded_smiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d8589",
   "metadata": {
    "papermill": {
     "duration": 0.008962,
     "end_time": "2024-06-25T13:08:07.668861",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.659899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fbcf659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.687398Z",
     "iopub.status.busy": "2024-06-25T13:08:07.687142Z",
     "iopub.status.idle": "2024-06-25T13:08:07.697826Z",
     "shell.execute_reply": "2024-06-25T13:08:07.697112Z"
    },
    "papermill": {
     "duration": 0.022056,
     "end_time": "2024-06-25T13:08:07.699661",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.677605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 9, 2, 18, 2, 2, 4, 13, 28, 13, 13, 13, 24, 2, 3, 13, 29, 14, 13, 24, 3, 13, 30, 13, 13, 24, 20, 13, 31, 13, 13, 13, 24, 8, 25, 13, 13, 31, 25, 11, 13, 30, 2, 24, 17, 4, 25, 4, 2, 25, 14, 13, 24, 3, 22, 2, 26, 5, 23, 24, 2, 2, 18, 2, 25, 2, 2, 24, 17, 4, 20, 25, 3, 37, 25, 14, 29, 25, 13, 13, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fast.batch_encode_plus(['BrBC#CCOc1ccc(CNc2nc(Nc3cc(-c4ccc(Cl)cc4)sc3C(=O)OC)nc(N[C@@H](CC#C)CC(=O-)N[Dy])n2)cc1'],max_length=142,padding='max_length')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caeb8fb",
   "metadata": {
    "papermill": {
     "duration": 0.008272,
     "end_time": "2024-06-25T13:08:07.716427",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.708155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We can see that Br, Cl and @@ have been successfully separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c4201b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.735035Z",
     "iopub.status.busy": "2024-06-25T13:08:07.734806Z",
     "iopub.status.idle": "2024-06-25T13:08:07.740974Z",
     "shell.execute_reply": "2024-06-25T13:08:07.740193Z"
    },
    "papermill": {
     "duration": 0.017534,
     "end_time": "2024-06-25T13:08:07.742890",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.725356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Br',\n",
       " 'B',\n",
       " 'C',\n",
       " '#',\n",
       " 'C',\n",
       " 'C',\n",
       " 'O',\n",
       " 'c',\n",
       " '1',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " '(',\n",
       " 'C',\n",
       " 'N',\n",
       " 'c',\n",
       " '2',\n",
       " 'n',\n",
       " 'c',\n",
       " '(',\n",
       " 'N',\n",
       " 'c',\n",
       " '3',\n",
       " 'c',\n",
       " 'c',\n",
       " '(',\n",
       " '-',\n",
       " 'c',\n",
       " '4',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " '(',\n",
       " 'Cl',\n",
       " ')',\n",
       " 'c',\n",
       " 'c',\n",
       " '4',\n",
       " ')',\n",
       " 's',\n",
       " 'c',\n",
       " '3',\n",
       " 'C',\n",
       " '(',\n",
       " '=',\n",
       " 'O',\n",
       " ')',\n",
       " 'O',\n",
       " 'C',\n",
       " ')',\n",
       " 'n',\n",
       " 'c',\n",
       " '(',\n",
       " 'N',\n",
       " '[',\n",
       " 'C',\n",
       " '@@',\n",
       " 'H',\n",
       " ']',\n",
       " '(',\n",
       " 'C',\n",
       " 'C',\n",
       " '#',\n",
       " 'C',\n",
       " ')',\n",
       " 'C',\n",
       " 'C',\n",
       " '(',\n",
       " '=',\n",
       " 'O',\n",
       " '-',\n",
       " ')',\n",
       " 'N',\n",
       " '[Dy]',\n",
       " ')',\n",
       " 'n',\n",
       " '2',\n",
       " ')',\n",
       " 'c',\n",
       " 'c',\n",
       " '1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fast.tokenize('BrBC#CCOc1ccc(CNc2nc(Nc3cc(-c4ccc(Cl)cc4)sc3C(=O)OC)nc(N[C@@H](CC#C)CC(=O-)N[Dy])n2)cc1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549136f0",
   "metadata": {
    "papermill": {
     "duration": 0.008687,
     "end_time": "2024-06-25T13:08:07.760122",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.751435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TEST on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371cdd4",
   "metadata": {
    "papermill": {
     "duration": 0.008497,
     "end_time": "2024-06-25T13:08:07.777184",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.768687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "only 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6ddb38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.795756Z",
     "iopub.status.busy": "2024-06-25T13:08:07.795504Z",
     "iopub.status.idle": "2024-06-25T13:08:07.798885Z",
     "shell.execute_reply": "2024-06-25T13:08:07.798161Z"
    },
    "papermill": {
     "duration": 0.014759,
     "end_time": "2024-06-25T13:08:07.800628",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.785869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "# smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "# smiles_enc = encode_smiles_batch(smiles.tolist(),max_length=142,batch_size = 4096*4)\n",
    "\n",
    "# smiles_enc = np.stack(smiles_enc)\n",
    "\n",
    "# test = pd.DataFrame(smiles_enc, columns = [f'm_enc{i}' for i in range(142)])\n",
    "# test.to_parquet('test_enc.parquet')\n",
    "# 100%|██████████| 103/103 [03:49<00:00,  2.23s/it]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d8e56",
   "metadata": {
    "papermill": {
     "duration": 0.008466,
     "end_time": "2024-06-25T13:08:07.817673",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.809207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa32804",
   "metadata": {
    "papermill": {
     "duration": 0.00856,
     "end_time": "2024-06-25T13:08:07.834846",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.826286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since some libraries, such as tokenizers, initialize some global states when used,  these states can cause problems after the process forks. So we'll explicitly set the environment variable ```TOKENIZERS_PARALLELISM=false``` to disable parallel processing for tokenizers. This will ensure that parallel processing is  no longer used after the process forks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e9d9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.853023Z",
     "iopub.status.busy": "2024-06-25T13:08:07.852761Z",
     "iopub.status.idle": "2024-06-25T13:08:07.856228Z",
     "shell.execute_reply": "2024-06-25T13:08:07.855546Z"
    },
    "papermill": {
     "duration": 0.014316,
     "end_time": "2024-06-25T13:08:07.857828",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.843512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e913d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:07.876222Z",
     "iopub.status.busy": "2024-06-25T13:08:07.876000Z",
     "iopub.status.idle": "2024-06-25T13:08:09.906941Z",
     "shell.execute_reply": "2024-06-25T13:08:09.906056Z"
    },
    "papermill": {
     "duration": 2.04265,
     "end_time": "2024-06-25T13:08:09.909045",
     "exception": false,
     "start_time": "2024-06-25T13:08:07.866395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.PREPROCESS:\n",
    "    if all_data:\n",
    "        train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n",
    "        smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n",
    "        assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n",
    "        assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n",
    "\n",
    "    else:\n",
    "        train_raw = pd.read_csv('/kaggle/input/leash-BELKA/train.csv',nrows = 1000)\n",
    "        smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values[:333]\n",
    "        HSA = train_raw[train_raw['protein_name']=='HSA'].reset_index(drop=True)\n",
    "        sEH = train_raw[train_raw['protein_name']=='sEH'].reset_index(drop=True)\n",
    "        assert (smiles!=HSA['molecule_smiles'].values).sum() == 0\n",
    "        assert (smiles!=sEH['molecule_smiles'].values).sum() == 0\n",
    "\n",
    "    smiles_enc = encode_smiles_parallel(smiles.tolist(), max_length=142, batch_size=4096*8)\n",
    "    del smiles\n",
    "    gc.collect()\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "\n",
    "    \n",
    "    train = pd.DataFrame(smiles_enc, columns = [f'm_enc{i}' for i in range(142)])\n",
    "    \n",
    "    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "    train.to_parquet('train_enc.parquet')\n",
    "\n",
    "    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "    smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "    smiles_enc = encode_smiles_batch(smiles.tolist(),max_length=142,batch_size = 4096*8)\n",
    "    \n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    \n",
    "    test = pd.DataFrame(smiles_enc, columns = [f'm_enc{i}' for i in range(142)])\n",
    "    test.to_parquet('test_enc.parquet')\n",
    "\n",
    "else:\n",
    "    if not CFG.predict:\n",
    "        train = pd.read_parquet('/kaggle/input/belka-chemical-encoding/train_enc.parquet')\n",
    "    test = pd.read_parquet('/kaggle/input/belka-chemical-encoding/test_enc.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974e7aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:09.927985Z",
     "iopub.status.busy": "2024-06-25T13:08:09.927556Z",
     "iopub.status.idle": "2024-06-25T13:08:09.931660Z",
     "shell.execute_reply": "2024-06-25T13:08:09.930892Z"
    },
    "papermill": {
     "duration": 0.015477,
     "end_time": "2024-06-25T13:08:09.933475",
     "exception": false,
     "start_time": "2024-06-25T13:08:09.917998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57112d03",
   "metadata": {
    "papermill": {
     "duration": 0.008451,
     "end_time": "2024-06-25T13:08:09.950309",
     "exception": false,
     "start_time": "2024-06-25T13:08:09.941858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ade5b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:09.968966Z",
     "iopub.status.busy": "2024-06-25T13:08:09.968736Z",
     "iopub.status.idle": "2024-06-25T13:08:11.844272Z",
     "shell.execute_reply": "2024-06-25T13:08:11.843353Z"
    },
    "papermill": {
     "duration": 1.887072,
     "end_time": "2024-06-25T13:08:11.846063",
     "exception": false,
     "start_time": "2024-06-25T13:08:09.958991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 142)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 142, 128)          4736      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 140, 32)           12320     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 138, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 136, 96)           18528     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 96)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              99328     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,717,059\n",
      "Trainable params: 1,717,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def my_model():\n",
    "    with strategy.scope():\n",
    "        INP_LEN = 142\n",
    "        NUM_FILTERS = 32\n",
    "        hidden_dim = 128\n",
    "        tokens_num = 37\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=(INP_LEN,), dtype='int32')\n",
    "        x = tf.keras.layers.Embedding(input_dim=tokens_num, output_dim=hidden_dim, input_length=INP_LEN, mask_zero = True)(inputs)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*2, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*3, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "        outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=CFG.LR, weight_decay=CFG.WD)\n",
    "        loss = 'binary_crossentropy'\n",
    "        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n",
    "        model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        weighted_metrics=weighted_metrics,\n",
    "        )\n",
    "        return model\n",
    "model = my_model()\n",
    "\n",
    "model.summary()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e52fa",
   "metadata": {
    "papermill": {
     "duration": 0.010443,
     "end_time": "2024-06-25T13:08:11.867456",
     "exception": false,
     "start_time": "2024-06-25T13:08:11.857013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc8896c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:11.889474Z",
     "iopub.status.busy": "2024-06-25T13:08:11.889197Z",
     "iopub.status.idle": "2024-06-25T13:08:21.655533Z",
     "shell.execute_reply": "2024-06-25T13:08:21.654184Z"
    },
    "papermill": {
     "duration": 9.780138,
     "end_time": "2024-06-25T13:08:21.657855",
     "exception": false,
     "start_time": "2024-06-25T13:08:11.877717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 13:08:14.698471: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-25 13:08:14.765407: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 8s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "FEATURES = [f'm_enc{i}' for i in range(142)]\n",
    "TARGETS = ['bind1', 'bind2', 'bind3']\n",
    "skf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42)\n",
    "\n",
    "all_preds = []\n",
    "if not CFG.predict:\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(train, train[TARGETS].sum(1))):\n",
    "\n",
    "        if fold not in CFG.SELECTED_FOLDS:\n",
    "            continue;\n",
    "\n",
    "        X_train = train.loc[train_idx, FEATURES]\n",
    "        y_train = train.loc[train_idx, TARGETS]\n",
    "        X_val = train.loc[valid_idx, FEATURES]\n",
    "        y_val = train.loc[valid_idx, TARGETS]\n",
    "\n",
    "        es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"model-{fold}.tf\",\n",
    "                                                            save_best_only=True, save_weights_only=True,\n",
    "                                                        mode='min')\n",
    "        reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=4, verbose=1)\n",
    "        model = my_model()\n",
    "        history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=CFG.EPOCHS,\n",
    "                callbacks=[checkpoint, reduce_lr_loss, es],\n",
    "                batch_size=CFG.BATCH_SIZE,\n",
    "                verbose=1,\n",
    "            )\n",
    "        model.load_weights(f\"model-{fold}.tf\")\n",
    "        model.load_weights(f\"/kaggle/input/re-encode-model/model-{fold}.tf\")\n",
    "\n",
    "        oof = model.predict(X_val, batch_size = CFG.BATCH_SIZE)\n",
    "        print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "\n",
    "        preds = model.predict(test, batch_size = CFG.BATCH_SIZE)\n",
    "        all_preds.append(preds)\n",
    "if CFG.predict:\n",
    "    model.load_weights(f\"/kaggle/input/re-encode-model/model-0.tf\")\n",
    "    preds = model.predict(test, batch_size = CFG.BATCH_SIZE)\n",
    "    all_preds.append(preds)\n",
    "preds = np.mean(all_preds, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c1d32",
   "metadata": {
    "papermill": {
     "duration": 0.013577,
     "end_time": "2024-06-25T13:08:21.685559",
     "exception": false,
     "start_time": "2024-06-25T13:08:21.671982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1067bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T13:08:21.714616Z",
     "iopub.status.busy": "2024-06-25T13:08:21.714275Z",
     "iopub.status.idle": "2024-06-25T13:08:28.262558Z",
     "shell.execute_reply": "2024-06-25T13:08:28.261219Z"
    },
    "papermill": {
     "duration": 6.565899,
     "end_time": "2024-06-25T13:08:28.265102",
     "exception": false,
     "start_time": "2024-06-25T13:08:21.699203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "tst['binds'] = 0\n",
    "tst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\n",
    "tst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\n",
    "tst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\n",
    "tst[['id', 'binds']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4914065,
     "sourceId": 8275617,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4964802,
     "sourceId": 8355401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4979606,
     "sourceId": 8375131,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4977435,
     "sourceId": 8387257,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30514,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 120.257672,
   "end_time": "2024-06-25T13:08:33.130276",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-25T13:06:32.872604",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
